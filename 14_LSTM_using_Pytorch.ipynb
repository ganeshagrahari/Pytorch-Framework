{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqcgTEFtXkwUWmxV5msRdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshagrahari/Pytorch-Framework/blob/main/14_LSTM_using_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyrJmnQ3MdN7",
        "outputId": "39e32a70-554e-4553-d70a-3e6542739d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "XS0qBPwdMlZ6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "C6HHnt7FNDci"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY5xmuRANSCL",
        "outputId": "da818ef6-fab2-420e-d9fb-d38f80bc5ee8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "-tFivP73Nfjp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build vocab\n",
        "vocab = {'<unk>' : 0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKdo-DG-Noyp",
        "outputId": "1bcbda8d-dcbf-4aae-dda0-756cbb35b654"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract sentences from data\n",
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "eh3_481tOBQO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence,vocab):\n",
        "  numerical_sentence = []\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "ornbVElyP7dL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numrical_sentences = []\n",
        "for sentence in input_sentences:\n",
        "  input_numrical_sentences.append(text_to_indices(word_tokenize(sentence.lower()),vocab))\n"
      ],
      "metadata": {
        "id": "0f7YW7efO5_f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numrical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ7kf3GrPWM0",
        "outputId": "cb3ae37e-ec2e-468a-c579-80407230ee15"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences = []\n",
        "for sentence in input_numrical_sentences:\n",
        "  for i in range(1,len(sentence)):\n",
        "    training_sequences.append(sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "LAAwTMNf8QLL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9iZRtm698iV",
        "outputId": "0bdbae17-d8db-4a55-fc09-d8610ac57675"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLTFIXbY-AR5",
        "outputId": "2bbda442-c838-478c-c95f-09fc3c4d1268"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [4, 5], [4, 5, 2], [4, 5, 2, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for sequence in training_sequences:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaxB6MkEB8RG",
        "outputId": "5360ecf5-1b54-41cb-9f1f-3eb1deb4f5fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEmtPFWZCRrp",
        "outputId": "dad6e418-79ba-4f17-9c3c-de04b5d324d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tarining_sequences = []\n",
        "for sequence in training_sequences:\n",
        "  padded_tarining_sequences.append([0]*(max(len_list)-len(sequence))+sequence)\n",
        ""
      ],
      "metadata": {
        "id": "frEWwFk0C4MU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_tarining_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCwY55-lFRF8",
        "outputId": "98959801-bf5a-4ccf-8850-35e1080a70c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tarining_sequences = torch.tensor(padded_tarining_sequences,dtype = torch.long)"
      ],
      "metadata": {
        "id": "fsPUloHJFTNr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tarining_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4pSq9yYFmFa",
        "outputId": "0f6da81f-6f0c-4937-e024-5befd778e3bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([942, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_tarining_sequences[:,:-1]\n",
        "y = padded_tarining_sequences[:,-1]"
      ],
      "metadata": {
        "id": "AAu5zsvEFn72"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbQFs_mTF2Mz",
        "outputId": "9bd46b8c-d2e4-4ed1-e4ef-cdc0f5dc9aea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xsdCp2YF2rL",
        "outputId": "4d468976-f504-459e-e780-910f89fec7e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   5,   2,   6,   7,   8,   9,  10,  11,   3,  12,  13,  14,\n",
              "         15,   6,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  18,  26,\n",
              "         27,  28,  29,  30,   5,   2,  31,  32,  27,   2,   6,  33,  31,  32,\n",
              "         27,   2,   6,   5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,\n",
              "         39,  34,  40,  28,  41,  12,  42,  30,  15,   5,   2,  43,  27,   2,\n",
              "         11,   3,  33,  45,  46,  47,   2,  48,  49,  50,  52,  53,   8,   9,\n",
              "         10,  54,   8,   9,  10,   8,  57,  58,  60,  59,  64,  65,  66,   2,\n",
              "         67,  43,  68,  69,  70,  50,  71,  72,  58,  73,  74,  46,  17,  75,\n",
              "         27,  76,   3,  33,  78,  74,  73,  72,  58,  79,  80,  81,  17,  75,\n",
              "         27,  76,   3,  82,  83,  84,  30,  85,  86,  87,  17,  88,  89,  33,\n",
              "         45,  86,  90,  17,  91,  27,   2,  89,  33,  93,  94,  95,  80,  96,\n",
              "         78,  36,  97,  85,  22,  87,  17,  89,  22,  65,  98,  99,  73, 100,\n",
              "          2,  91,  30,  65,  86, 101,   2, 102, 103,  33,  76, 105, 106,  24,\n",
              "        107, 108, 109, 108, 110, 111,  27,   2,   6,  69,  70,  50, 112,  33,\n",
              "        113,  30,   5,   2, 110,  32,  27,  93,   2,  88,  95,  33,  78,  93,\n",
              "          2,  95, 115, 116, 117,  30,   5,   2, 118, 119, 109,   2, 120, 121,\n",
              "          2,  95,  33,  45,  86,  46, 124,   1,   2, 125, 102,  33,  45,  90,\n",
              "         17, 126, 127,  94, 128, 129, 130, 131,  89, 132,  22, 133,  17, 131,\n",
              "        134,  30,  86, 135,  76,   6,  85,  86, 136, 127,  17, 137, 138,  33,\n",
              "         78, 139,  30, 136, 140,  78,  65,  86, 141,   2,   3, 142,   2, 143,\n",
              "         33,  78,  22,  65, 141,   2,   3, 144,  30,  86, 145, 142,   2, 143,\n",
              "         78,  45,  86,  46, 146,  24, 107,  93,   2, 147, 148,  33,  78, 132,\n",
              "         22,  25,   2, 149,  22,  45,  46, 146,  24, 107,  93,   2, 147, 150,\n",
              "        142, 151, 152,  30, 135,  86,  23,  24, 153,   2, 154,  33, 155,  82,\n",
              "        156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
              "         78,  22,  23,  24, 160, 161,   2, 154, 162,  30,  44, 135,  63,  64,\n",
              "        142,   2,   3,  33,  30,  65,  44, 163,  22,  33,  65, 126, 164, 165,\n",
              "        166, 167, 168, 170, 171, 135,  44,  23,  24,  25,  94,  26,  33, 151,\n",
              "        172, 173, 174, 175,  33,  23,  24,  25,  93, 151,  18,  26, 176,  94,\n",
              "        175,  30,  68,   5,   2, 177,   8,  94, 175,  69,  70,  50, 178,  44,\n",
              "        179,   2, 180, 181,  27,  28,  41,  93, 165, 132,  33,  77,  78,   2,\n",
              "          3,  16,  17,  18,  19,  20,  30,   5,   2, 183,  27,  18,  19,  33,\n",
              "        184,  85,  86, 179, 176, 185, 186,  78, 187, 135,  86,  23,  24, 179,\n",
              "        188, 176, 189, 190, 174, 185, 190, 191,   2, 183, 192,   5, 193, 194,\n",
              "        127,   2, 195,  22,  25,   2, 149,  30,  36, 196,  22,  65, 141, 144,\n",
              "         22, 155,  82, 156,  23,  24, 197,   8,  17, 108,  24, 198,  30,  85,\n",
              "         86, 155,  82, 156, 199,   2,   6, 200, 201,   2, 149,  30,   4,   5,\n",
              "          2, 202, 203,  33,  90,  17,  34, 194, 202, 192, 127,   2, 195,  22,\n",
              "         23, 204,   2, 149,  30, 136, 205, 206, 207,  73,  86, 136,  81, 146,\n",
              "         24,  25,   2, 149, 176,   2, 175,  78,   4, 208,  86, 135,  33,  23,\n",
              "         24, 163, 164, 109, 209,  17, 126, 165, 166, 167, 168, 211, 212, 214,\n",
              "         65,  86, 215,   2, 131, 216, 176,   2, 175,  33, 217,   5, 218,  78,\n",
              "         36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
              "         30, 184,  22,  23, 222,  19, 176, 223, 186,  78,  22,  45,  46, 146,\n",
              "         24, 100,  93,   2, 147, 131,  95, 142,   2, 192,  27, 223, 186,  24,\n",
              "        224, 191, 225, 200, 223, 190,  22,  45,  23,  24, 226,   2,  19, 188,\n",
              "         30, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,  12,\n",
              "        174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,   2,\n",
              "        131,  95, 213, 229,   0,  30, 232, 183,   5,  81, 233,  33,  27,   2,\n",
              "        235,   6,   7,  30,  65,  86, 236, 237, 142,  63,  27,  17, 238, 200,\n",
              "          2,  89,  33,  45,  23,  24, 239,  17, 105, 240, 233, 142, 151, 152,\n",
              "         73,  94, 241,  45, 163,  22,   8,  17, 242, 176, 242, 238, 243,  89,\n",
              "         86, 141,   2,   3, 140,  78,  65,  86, 244, 245, 147, 246, 247,  33,\n",
              "         78, 248, 249, 147, 246, 238, 142,   2, 238, 243, 105, 240,  30, 136,\n",
              "        205, 206, 207,  73,  86, 136,  81, 146,  24,  25,   2, 149, 176,   2,\n",
              "        175,  78,   4, 208,  86, 135,  33,  23,  24, 163, 164, 109, 209,  17,\n",
              "        126, 165, 166, 167, 250,  73, 252, 253, 170, 212,   5,   2, 254,  24,\n",
              "         90,   2, 251,  33,  80, 116, 256,  50,  23,  24, 179,   2, 180,   7,\n",
              "         27,  28,  41,  23,  24, 257,  93,   2,   6, 258,  30, 136, 259, 140,\n",
              "         30, 123,  65,  86, 179, 149,  27,   2, 260,  35,  33,  45,  90,  17,\n",
              "        177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22, 179,   8,\n",
              "          2, 261, 108,  30,  23, 219, 262, 252, 253,   5,  17,  75,  27,  76,\n",
              "          3,  30,   4, 263, 264, 252, 253,  33,   5,  24, 265, 262, 252, 253,\n",
              "        266,  81, 267, 252, 268,  30,  36,  44, 269, 268,  22, 270, 271, 174,\n",
              "          8, 262, 272,  97, 273, 274,  30,  36,  85,  22,  80, 275,  24, 141,\n",
              "         76,   6, 248,   8, 276,  78,  86, 136, 277,  22,  45,  46, 278,  30,\n",
              "         68,   5,   4, 263, 264, 252, 253, 280,  95, 282,  95, 158, 283, 284,\n",
              "        176, 286, 287, 288])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index],self.y[index]"
      ],
      "metadata": {
        "id": "RUs4ZzpJF3_2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(x,y)"
      ],
      "metadata": {
        "id": "e3rJLMrbGuKD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH4MgFKNG0JH",
        "outputId": "30832309-0c09-409a-b776-0cdc5edaa239"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
              " tensor(2))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "IMpqjS3VG3cQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input, output in dataloader:\n",
        "  print(input,output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm3o3VpoHB_c",
        "outputId": "7bc6e96d-28ae-4401-b516-090be8547530"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,   0,   0,  ...,  23,  24, 153],\n",
            "        [  0,   0,   0,  ...,   0,  22,  23],\n",
            "        [  0,   0,   0,  ...,   2,  31,  32],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,  92],\n",
            "        [  0,   0,   0,  ...,  76,   6,  85],\n",
            "        [  0,   0,   0,  ...,  12,  42,  30]]) tensor([  2,  24,  27, 158,  34, 251, 168, 135, 177,  22, 152, 190, 115,  95,\n",
            "        110,  39, 223, 263, 211,  19,   2,  32,   5,  97,  83,  23, 270,  30,\n",
            "         85,  78,  86,  15])\n",
            "tensor([[  0,   0,   0,  ..., 245, 147, 246],\n",
            "        [  0,   0,   0,  ...,   6, 200, 201],\n",
            "        [  0,   0,   0,  ..., 132,  22, 133],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  17, 108,  24],\n",
            "        [  0,   0,   0,  ..., 142, 151, 152],\n",
            "        [  0,   0,   0,  ...,   2, 180, 181]]) tensor([247,   2,  17, 128, 195,  30,  95,  74,   2,  30,   8,  46, 238,  69,\n",
            "        224,  10, 227,  30,   2,  27,  23,  27,  78,  22, 195,  38, 126,  65,\n",
            "         13, 198, 132,  27])\n",
            "tensor([[  0,   0,   0,  ...,   0,  21,  65],\n",
            "        [  0,   0,   0,  ...,   0, 169, 170],\n",
            "        [  0,   0,   0,  ..., 140,  30, 123],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  74,  73,  72],\n",
            "        [  0,   0,   0,  ...,  43,  68,  69],\n",
            "        [  0,   0,   0,  ...,   0,   0,  92]]) tensor([ 44, 171,  65, 248, 132,  53, 146,  24,  97, 146, 164,  90, 232,  85,\n",
            "         22,   3,  22,  93,   3,  49, 112, 248,   2,  95, 262,  78,  86,   2,\n",
            "         26,  58,  70,  78])\n",
            "tensor([[  0,   0,   0,  ..., 183, 192,   5],\n",
            "        [  0,   0,   0,  ...,  21,  65,  44],\n",
            "        [  0,   0,   0,  ..., 107, 108, 109],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,  95],\n",
            "        [  0,   0,   0,  ..., 142,  63,  27],\n",
            "        [  0,   0,   0,  ...,   0,   0,  86]]) tensor([193, 163, 108,   3,  48,  89, 135,  23,  30,  73, 267, 102, 266, 272,\n",
            "          2,   5,   6,   2,  30,  74, 250,   6, 144, 164, 100, 188,  73, 205,\n",
            "        262, 158,  17, 136])\n",
            "tensor([[  0,   0,   0,  ...,  90,  17, 177],\n",
            "        [  0,   0,   0,  ..., 216, 176,   2],\n",
            "        [  0,   0,   0,  ..., 164, 109, 209],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  18,  19,  20],\n",
            "        [  0,   0,   0,  ...,   2,  48,  49],\n",
            "        [  0,   0,   0,  ...,  73, 100,   2]]) tensor([ 24, 175,  17,  46, 101,   5, 149, 176,  45,  19,  12,  86,  17,  78,\n",
            "         45,  45,  72, 223,  95,  66,  95, 194,   3,  50, 178, 197,  33, 243,\n",
            "        252,  30,  50,  91])\n",
            "tensor([[  0,  76, 217,  ..., 226,   2,  19],\n",
            "        [  0,   0,   0,  ...,  25,  94,  26],\n",
            "        [  0,   0,   0,  ...,  22,  45,  90],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 217,   5, 218],\n",
            "        [  0,   0,   0,  ..., 202, 192, 127],\n",
            "        [  0,   0,   0,  ...,   3,  12,  13]]) tensor([188,  33,  17, 160,  19,   8, 100,  17,   2, 200,  75,  29, 174, 136,\n",
            "         45,   8, 240,  22,  33,  28, 253,   3, 142,  41,  17, 142, 133,  76,\n",
            "         69,  78,   2,  14])\n",
            "tensor([[  0,   0,   0,  ...,   2, 149,  30],\n",
            "        [  0,   0,   0,  ...,   1,   2, 125],\n",
            "        [  0,   0,   0,  ...,   0,  22,  23],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  30,  68,   5],\n",
            "        [  0,   0,   0,  ...,   4,  85,  86],\n",
            "        [  0,   0,   0,  ...,   0,  85,  86]]) tensor([ 36, 102,  24,   2, 259,  33,  95,  65,  73,  34, 212,  38, 163,  76,\n",
            "        202,  44,  17,   2,   2,  86,  50,  23, 163, 120,  44, 208, 269,   5,\n",
            "        246,   2, 155, 141])\n",
            "tensor([[  0,   0,   0,  ..., 111,  27,   2],\n",
            "        [  0,   0,   0,  ..., 160, 161,   2],\n",
            "        [  0,   0,   0,  ...,   4,   5,   2],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  69,  70,  50],\n",
            "        [  0,   0,   0,  ..., 262, 272,  97],\n",
            "        [  0,   0,   0,  ...,   2,  31,   6]]) tensor([  6, 154,  31,   2, 268, 109, 221,  30, 214,   2,  30, 136,  23,  22,\n",
            "        238,  86,  78,   5,  80, 147,  24,  96, 151,  30,  16, 135,   2, 157,\n",
            "          2,  71, 273,   7])\n",
            "tensor([[  0,   0,   0,  ...,   5, 193, 194],\n",
            "        [  0,   0,   0,  ..., 165, 166, 167],\n",
            "        [  0,   0,   0,  ...,  86, 136, 205],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 246, 238, 142],\n",
            "        [  0,   0,   0,  ...,  94, 128, 129],\n",
            "        [  0,   0,   0,  ..., 126, 165, 166]]) tensor([127, 168, 206, 186, 238, 179, 209, 148, 187,  85,  78, 260,   2,  45,\n",
            "        109,  33, 264,  50, 151, 201,  78,  64,  89,   2,  94,  65, 109, 179,\n",
            "         80,   2, 130, 167])\n",
            "tensor([[  0,   0,   0,  ...,  93,   2, 147],\n",
            "        [  0,   0,   0,  ...,   0,   0,   4],\n",
            "        [  0,   0,   0,  ...,  44, 269, 268],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 197,   8,  17],\n",
            "        [  0,   0,   0,  ..., 221,  30, 184],\n",
            "        [  0,   0,   0,  ..., 184,  85,  86]]) tensor([150,   5,  22, 174, 246,  23,  17,  77,   4,   6,  24, 136, 183,  30,\n",
            "         81,  33,  33,  76,   7,  24,  17, 249,  24,   4,  24,  85, 252,  86,\n",
            "         24, 108,  22, 179])\n",
            "tensor([[  0,   0,   0,  ..., 180, 181,  27],\n",
            "        [  0,   0,   0,  ...,  22,  23, 131],\n",
            "        [  0,   0,   0,  ...,  18,  19,  33],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  21, 135,  86],\n",
            "        [  0,   0,   0,  ...,  27,  93,   2],\n",
            "        [  0,   0,   0,  ...,   2, 238, 243]]) tensor([ 28, 164, 184,  40, 147,  23,  24, 183, 229, 263,  22, 116,  85,  33,\n",
            "          7, 141, 223, 142, 185,  30,  28,  22, 264, 154, 149,  78, 174,  27,\n",
            "          4,  23,  88, 105])\n",
            "tensor([[  0,   0,   0,  ...,  78,  36, 219],\n",
            "        [  0,   0,   0,  ...,  89,  33,  45],\n",
            "        [  0,   0,   0,  ..., 231, 232, 183],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0, 123,  45],\n",
            "        [  0,   0,   0,  ...,  95, 213, 229],\n",
            "        [  0,   0,   0,  ...,  73,  22,  23]]) tensor([220,  86,   5, 107, 137,   5, 243, 252, 165,  20,  30,  57,  18, 196,\n",
            "        146,  24,  20, 252, 180,  90, 216,  22,  22,  65,   2, 204,   3,  94,\n",
            "         63,  86,   0, 131])\n",
            "tensor([[  0,   0,   0,  ...,  86, 155,  82],\n",
            "        [  0,   0,   0,  ...,  27,   2, 235],\n",
            "        [  0,   0,   0,  ...,  85,  22,  87],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  68,   5,   2],\n",
            "        [  0,   0,   0,  ..., 172, 173, 174],\n",
            "        [  0,   0,   0,  ...,  86, 136, 259]]) tensor([156,   6,  17, 136, 116,  87,  17, 245,  19,  24, 268, 113,  18,   2,\n",
            "        151, 139, 275,   8,  86,  35,   6,  31, 136, 138, 152,  30,  75,  24,\n",
            "        142, 177, 175, 140])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0, 255],\n",
            "        [  0,   0,   0,  ...,   0,   0,  61],\n",
            "        [  0,   0,   0,  ...,  24, 179,   7],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  24, 179, 188],\n",
            "        [  0,   0,   0,  ...,  23, 222,  19],\n",
            "        [  0,   0,   0,  ..., 205, 206, 207]]) tensor([ 80,  59,  27,  30,  22, 190,  86, 126,   2,   2, 183,  18,  98, 278,\n",
            "          2,  12,  22, 192, 174,  60, 199, 283,  46,  80, 242,  23, 200, 125,\n",
            "        286, 176, 176,  73])\n",
            "tensor([[  0,   0,   0,  ...,  17, 137, 138],\n",
            "        [  0,   0,   0,  ..., 215,   2, 131],\n",
            "        [  0,   0,   0,  ...,   0,  45,  72],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 155,  82, 156],\n",
            "        [  0,   0,   0,  ...,  24, 197,   8],\n",
            "        [  0,   0,   0,  ...,  82, 156,  23]]) tensor([ 33, 216,  58,  22,   4,  95,  24,  22,  78,  18,  18,  45,   7, 256,\n",
            "          2,  73,   2, 135,  26,  15,   2,   2,   2,  19,  23,  86,  78, 121,\n",
            "          2,  23,  17,  24])\n",
            "tensor([[  0,   0,   0,  ..., 149, 176,   2],\n",
            "        [  0,   0,   0,  ...,   2, 183, 192],\n",
            "        [  0,   0,   0,  ...,  22, 133,  17],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  92,  78, 139],\n",
            "        [  0,   0,   0,  ...,  86,  23,  24],\n",
            "        [  0,   0,   0,  ...,  66,   2,  67]]) tensor([175,   5, 131, 165,  30, 184,   2,  22,  86,  46,  33,  30, 109, 277,\n",
            "        127, 147, 175, 215, 147, 252, 151,  30,  24,  30,  93,  30,  89, 134,\n",
            "        108,  30, 153,  43])\n",
            "tensor([[  0,   0,   0,  ...,  65,  66,   2],\n",
            "        [  0,   0,   0,  ..., 285, 176, 286],\n",
            "        [  0,   0,   0,  ...,   0,  86, 136],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 192,  27, 223],\n",
            "        [  0,   0,   0,  ...,  17,  88,  89],\n",
            "        [  0,   0,   0,  ..., 136, 205, 206]]) tensor([ 67, 287, 205, 209, 141,  86,  50, 105,  35, 172,  22,  86, 110,  82,\n",
            "          2,  27,  33,   5,   5, 176,  81,  10, 179,  82, 152,  33,  30,  15,\n",
            "         87, 186,  33, 207])\n",
            "tensor([[  0,   0,   0,  ...,   2, 180,   7],\n",
            "        [  0,   0,  76,  ...,  24, 226,   2],\n",
            "        [  0,   0,   0,  ...,  58,  79,  80],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   4,   5,   2],\n",
            "        [  0,   0,   0,  ...,   0,   0,  45],\n",
            "        [  0,   0,   0,  ...,   4,   5,   2]]) tensor([ 27,  19,  81, 190,  24,  25,  94,  32,   7,  31, 194,  33,  12, 166,\n",
            "          2,  33,  24,   5, 127, 282,   3,  41,  33,  37,   2, 162, 149,  64,\n",
            "         78, 202,  44, 254])\n",
            "tensor([[  0,   0,   0,  ..., 136, 277,  22],\n",
            "        [  0,   0,   0,  ..., 265, 262, 252],\n",
            "        [  0,   0,   0,  ...,  33,  45,  86],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  24, 153,   2],\n",
            "        [  0,   0,   0,  ...,  86, 136, 205],\n",
            "        [  0,   0,   0,  ...,   0,  85,  86]]) tensor([ 45, 253,  90, 212,  23,  70,   2, 135,  22,  76, 244,  45, 191, 119,\n",
            "        179, 237,  93, 140,  65,  28,  86,  78,  36,  82, 192,  58,  84,  27,\n",
            "        118, 154, 206, 145])\n",
            "tensor([[  0,   0,   0,  ..., 183,   5,  81],\n",
            "        [  0,   0,   0,  ...,  46, 146,  24],\n",
            "        [  0,   0,   0,  ...,   4,   5,   2],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  32,  27,   2],\n",
            "        [  0,   0,   0,  ...,  22,  65, 141],\n",
            "        [  0,   0,   0,  ...,  45,  44, 135]]) tensor([233, 107,  43,   2,  33, 175, 218,  24,  11,  27,  45, 100,   2, 185,\n",
            "         30, 165, 170, 260, 135,  65,  68, 228,  33,   2,   2,  30,   8, 142,\n",
            "        146,   6, 144,  63])\n",
            "tensor([[  0,   0,   0,  ..., 272,  97, 273],\n",
            "        [  0,   0,   0,  ...,  18,  19,  20],\n",
            "        [  0,   0,   0,  ..., 241,  45, 163],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 179, 188, 176],\n",
            "        [  0,   0,   0,  ...,  85,  86,  87],\n",
            "        [  0,   0,   0,  ..., 213, 214,  65]]) tensor([274,  21,  22, 143, 191,  17, 131,  11,  94, 222,  24, 217,  73,  78,\n",
            "         41,   2,  33,   2,  73,  24,   2,  30,  88,  17,   8, 242,  27, 159,\n",
            "         86, 189,  17,  86])\n",
            "tensor([[  0,   0,   0,  ...,  86, 215,   2],\n",
            "        [  0,   0,   0,  ..., 104,  76, 105],\n",
            "        [  0,   0,   0,  ...,  23,  24, 163],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  93,   2, 147],\n",
            "        [  0,   0,   0,  ..., 238, 200,   2],\n",
            "        [  0,   0,   0,  ...,  94, 175,  69]]) tensor([131, 106, 164, 155, 176, 175, 156, 253,  28, 146,   9, 240,  10,  94,\n",
            "        257,  25,  86,  30,  65,  22,  46,  24, 258,   5,   2,   2,  78,  33,\n",
            "         82, 131,  89,  70])\n",
            "tensor([[  0,   0,   0,  ...,   5,  17,  75],\n",
            "        [  0,   0,   0,  ...,  86, 179, 149],\n",
            "        [  0,   0,   0,  ...,  22,  23,  24],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  46, 146,  24],\n",
            "        [  0,   0,   0,  ..., 140,  78,  65],\n",
            "        [  0,   0,   0,  ...,  23,  24, 226]]) tensor([ 27,  27, 179,  25,  24,  72,   2, 181,  73, 265,  28, 103,   6,   8,\n",
            "         27,  81,  17, 155,  65, 235,  30,  86,  42,  33,  65,   2,  93, 236,\n",
            "         17, 100,  86,   2])\n",
            "tensor([[  0,   0,   0,  ...,   2, 195,  22],\n",
            "        [  0,   0,   0,  ..., 200, 201,   2],\n",
            "        [  0,   0,   0,  ...,  86, 136, 140],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   2, 110,  32],\n",
            "        [  0,   0,   0,  ...,   0,   0,   9],\n",
            "        [  0,   0,   0,  ...,   0,   0,  22]]) tensor([ 23, 149,  78,   2, 132,  93,  16,   5,   2,   5,  33,   4,  45, 238,\n",
            "         22, 132,  36, 126,  45,   3, 180, 149, 136,  30, 192,  36, 163, 253,\n",
            "         65,  27,  54,  45])\n",
            "tensor([[  0,   0,   0,  ...,  24, 100,   2],\n",
            "        [  0,   0,   0,  ...,   0,   2,  31],\n",
            "        [  0,   0,   0,  ...,   0, 234,  27],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,  51],\n",
            "        [  0,   0,   0,  ..., 278,  30,  68],\n",
            "        [  0,   0,   0,  ...,  17, 126, 165]]) tensor([131,  32,   2, 219,  24,  65,  36, 213, 271, 186,   2,  78,   2,  30,\n",
            "        226, 149,   2, 165,  90, 176,   6,  24,   3,  27, 252, 127,   5, 126,\n",
            "        140,  52,   5, 166])\n",
            "tensor([[  0,   0,   0,  ...,   2, 131,  95],\n",
            "        [  0,   0,   0,  ...,   2, 260,  35],\n",
            "        [  0,   0,   0,  ...,  22,  90,  17],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  58,  73,  74],\n",
            "        [  0,   0,   0,  ..., 153,   2, 154],\n",
            "        [  0,   0,   0,  ...,  51,  53,   8]]) tensor([213,  33,  34, 276, 261, 176,  27, 253,  33, 208,  46,  76, 288,  86,\n",
            "         36,  30,  89,   3, 207,   2,  41, 241,   2,   1,  34,  17, 280,  44,\n",
            "        239,  46,  30,   9])\n",
            "tensor([[  0,   0,   0,  ...,   2, 147, 148],\n",
            "        [  0,   0,   0,  ..., 252, 253, 266],\n",
            "        [  0,   0,   0,  ..., 135,  63,  64],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 106,  24, 107],\n",
            "        [  0,   0,   0,  ...,  27,  28,  41],\n",
            "        [  0,   0,   0,  ..., 253,   5,  17]]) tensor([ 33,  81, 142, 167,  27, 156, 262,   2, 153,  33,  86,  46,   2,   9,\n",
            "         93, 151,   2,   2,  47,  30,  23,  26, 149,  76,  25, 170,   2,  33,\n",
            "         33, 108,  93,  75])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,  22],\n",
            "        [  0,   0,   0,  ...,  27,   2,   6],\n",
            "        [  0,   0,   0,  ...,  81, 146,  24],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,  45,  44],\n",
            "        [  0,   0,   0,  ...,  22,  23,  24],\n",
            "        [  0,   0,   0,  ...,   5,   2, 177]]) tensor([ 90,   5,  25, 166,  94,   6,  24, 142,  23,  23,  22, 179,  35, 143,\n",
            "        129,  30, 233, 147, 141,  85, 225,  44, 167, 142, 200,   6,  23,   2,\n",
            "        203, 135,  25,   8])\n",
            "tensor([[  0,   0,   0,  ...,  46, 278,  30],\n",
            "        [  0,   0,   0,  ...,   0,   1,   2],\n",
            "        [  0,   0,   0,  ...,  45,  86,  46],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,  86],\n",
            "        [  0,   0,   0,  ...,   3, 140,  78],\n",
            "        [  0,   0,   0,  ...,  25,   2, 149]]) tensor([ 68,   3, 146,  86,  69,   2, 132,   8, 111,  93, 176,   8, 284,  27,\n",
            "        151,   6, 219, 173,  45,  22, 124,  93,  91,  23,  68,   2, 107, 142,\n",
            "         95, 136,  65, 176])\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 185,\n",
            "         191,   2, 183, 192,   5, 193, 194, 127,   2, 195,  22,  25,   2, 149,\n",
            "          30,  36, 196,  22,  65],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          86, 136, 259, 140,  30],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,  65,  44, 179,   2, 180, 181,  27,\n",
            "          28,  41,  93, 165, 132],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0, 104,  76],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85,  86,\n",
            "         145, 142,   2, 143,  78],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,  22,  45,  90,  17, 126, 127,\n",
            "          94, 128, 129, 130, 131],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0, 182,  77,  78],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  77,\n",
            "          78,  74,  73,  72,  58],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 155,  82,\n",
            "         156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
            "          78,  22,  23,  24, 160],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          21,  65,  44, 163,  22],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,  86, 136, 205, 206, 207,  73,\n",
            "          86, 136,  81, 146,  24],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,  22,  45,  90,  17, 177,  24, 179,   7,  27, 260,\n",
            "          35, 142, 151, 152, 132],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 114,  78,\n",
            "          93,   2,  95, 115, 116],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,  92,  93,  94,  95,  80,  96,  78,  36,  97,  85,  22,  87,\n",
            "          17,  89,  22,  65,  98]]) tensor([141, 123,  33, 105,  45,  89,   2,  79, 161,  33,  25,  22, 117,  99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  class LSTMModel(nn.Module):\n",
        "    def __init__(self,vocab_size):\n",
        "      super().__init__()\n",
        "      self.embedding = nn.Embedding(vocab_size,100)\n",
        "      self.lstm = nn.LSTM(100,150,batch_first=True)\n",
        "      self.fc = nn.Linear(150,vocab_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "      embedded = self.embedding(x)\n",
        "      intermediate_hidden_state,(final_hidden_state,final_cell_state)=self.lstm(embedded)\n",
        "      output = self.fc(final_hidden_state.squeeze(0))\n",
        "\n",
        "      return output"
      ],
      "metadata": {
        "id": "zAm3BrRSHI_J"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(289,100)\n",
        "y = nn.LSTM(100,150,batch_first=True)\n"
      ],
      "metadata": {
        "id": "u0x0PmkDYLyQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = dataset[0][0].unsqueeze(0)"
      ],
      "metadata": {
        "id": "l-8E6HrVYdi9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = x(a)"
      ],
      "metadata": {
        "id": "M5FrFilnYm_A"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c ,d =y(b)"
      ],
      "metadata": {
        "id": "obolElY8Y0iM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.shape #set of all intermediate hidden states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znY6P_PdY8qh",
        "outputId": "6bf8ccf7-9535-4de3-c8ee-60ccf0744a7c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 61, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e, f = d"
      ],
      "metadata": {
        "id": "BbT_g8bkZKUu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNUUcoTvZgGs",
        "outputId": "64089e7a-ef95-422b-b479-6a658d68aaad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6REljJMZiLs",
        "outputId": "a2044446-70de-452e-b2cd-7748ca478c9e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(150,289)"
      ],
      "metadata": {
        "id": "57Mw4ecNZndp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z(f.squeeze(0)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPUSSksFZx22",
        "outputId": "9bdf9c8b-6cfe-4f6f-ee6c-7ec039a106c5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 289])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "nlkk6w6pZ2Za"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "JTMLNe-Ma55c"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqSeF8rqbKZr",
        "outputId": "fe558484-c6dd-4b66-80a6-42c4ecd1cde8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "0rdpa2-YbPjy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_x,batch_y in dataloader:\n",
        "    batch_x,batch_y =batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss+=loss.item()\n",
        "  print(f\"Epoch: {epoch+1},loss:{total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUrPsoV8bjWz",
        "outputId": "3df90210-e5a4-46a0-f3ff-fd663a989565"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1,loss:165.7983\n",
            "Epoch: 2,loss:147.9159\n",
            "Epoch: 3,loss:136.0380\n",
            "Epoch: 4,loss:123.3238\n",
            "Epoch: 5,loss:110.8066\n",
            "Epoch: 6,loss:99.2913\n",
            "Epoch: 7,loss:88.9425\n",
            "Epoch: 8,loss:79.3817\n",
            "Epoch: 9,loss:70.2991\n",
            "Epoch: 10,loss:62.2151\n",
            "Epoch: 11,loss:55.5910\n",
            "Epoch: 12,loss:48.8310\n",
            "Epoch: 13,loss:43.0809\n",
            "Epoch: 14,loss:37.7605\n",
            "Epoch: 15,loss:33.3995\n",
            "Epoch: 16,loss:29.3730\n",
            "Epoch: 17,loss:26.2130\n",
            "Epoch: 18,loss:23.0582\n",
            "Epoch: 19,loss:20.3071\n",
            "Epoch: 20,loss:18.0002\n",
            "Epoch: 21,loss:16.3312\n",
            "Epoch: 22,loss:14.8036\n",
            "Epoch: 23,loss:13.4919\n",
            "Epoch: 24,loss:12.2376\n",
            "Epoch: 25,loss:11.3930\n",
            "Epoch: 26,loss:10.6338\n",
            "Epoch: 27,loss:9.7597\n",
            "Epoch: 28,loss:9.0905\n",
            "Epoch: 29,loss:8.7391\n",
            "Epoch: 30,loss:8.3564\n",
            "Epoch: 31,loss:7.7131\n",
            "Epoch: 32,loss:7.3258\n",
            "Epoch: 33,loss:6.9803\n",
            "Epoch: 34,loss:6.7634\n",
            "Epoch: 35,loss:6.4294\n",
            "Epoch: 36,loss:6.2415\n",
            "Epoch: 37,loss:5.9654\n",
            "Epoch: 38,loss:5.6792\n",
            "Epoch: 39,loss:5.5754\n",
            "Epoch: 40,loss:5.5341\n",
            "Epoch: 41,loss:5.2709\n",
            "Epoch: 42,loss:5.1591\n",
            "Epoch: 43,loss:5.1088\n",
            "Epoch: 44,loss:4.9020\n",
            "Epoch: 45,loss:4.7753\n",
            "Epoch: 46,loss:4.6879\n",
            "Epoch: 47,loss:4.7679\n",
            "Epoch: 48,loss:4.7113\n",
            "Epoch: 49,loss:4.5481\n",
            "Epoch: 50,loss:4.4749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "def prediction(model,vocab,text):\n",
        "  #tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  #text -> numerical indices\n",
        "  numerical_text = text_to_indices(tokenized_text,vocab)\n",
        "\n",
        "  #padding\n",
        "  padded_text = torch.tensor([0]*(61-len(numerical_text))+ numerical_text,dtype = torch.long).unsqueeze(0)\n",
        "\n",
        "  #send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  #predicted index\n",
        "  value, index = torch.max(output,dim = 1)\n",
        "  #merge with text\n",
        "  return text + \" \"+list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "OLDvNOSwc59v"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model,vocab,\"the course after making\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CeQbzMABN7hA",
        "outputId": "5e5a8f97-bf68-4e56-a8db-4b7a1294a14c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the course after making the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "num_token = 10\n",
        "input_text = \"the course after making\"\n",
        "for i in range(num_token):\n",
        "  output_text = prediction(model,vocab,input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JgcMzv7OTBR",
        "outputId": "41dd093e-4c06-4294-df25-b796e0467581"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the course after making the\n",
            "the course after making the payment\n",
            "the course after making the payment .\n",
            "the course after making the payment . what\n",
            "the course after making the payment . what is\n",
            "the course after making the payment . what is the\n",
            "the course after making the payment . what is the refund\n",
            "the course after making the payment . what is the refund policy\n",
            "the course after making the payment . what is the refund policy ?\n",
            "the course after making the payment . what is the refund policy ? ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D62u_eikQf8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}